{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Homework 8 - Anomaly Detection**\n\nIf there are any questions, please contact mlta-2022spring-ta@googlegroups.com\n\nSlide:    [Link]()ã€€Kaggle: [Link](https://www.kaggle.com/c/ml2022spring-hw8)","metadata":{"id":"YiVfKn-6tXz8"}},{"cell_type":"markdown","source":"# Set up the environment\n","metadata":{"id":"bDk9r2YOcDc9"}},{"cell_type":"markdown","source":"## Package installation","metadata":{"id":"Oi12tJMYWi0Q"}},{"cell_type":"code","source":"# Training progress bar\n!pip install -q qqdm","metadata":{"id":"7LexxyPWWjJB","execution":{"iopub.status.busy":"2022-05-09T08:08:16.568722Z","iopub.execute_input":"2022-05-09T08:08:16.568988Z","iopub.status.idle":"2022-05-09T08:08:25.72486Z","shell.execute_reply.started":"2022-05-09T08:08:16.568961Z","shell.execute_reply":"2022-05-09T08:08:25.723916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Downloading data","metadata":{"id":"DCgNXSsEWuY7"}},{"cell_type":"code","source":"# !wget https://github.com/MachineLearningHW/HW8_Dataset/releases/download/v1.0.0/data.zip","metadata":{"id":"SCLJtgF2BLSK","execution":{"iopub.status.busy":"2022-05-09T08:08:25.728687Z","iopub.execute_input":"2022-05-09T08:08:25.728905Z","iopub.status.idle":"2022-05-09T08:08:25.734316Z","shell.execute_reply.started":"2022-05-09T08:08:25.728879Z","shell.execute_reply":"2022-05-09T08:08:25.733444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !unzip data.zip","metadata":{"id":"0K5kmlkuWzhJ","execution":{"iopub.status.busy":"2022-05-09T08:08:25.735598Z","iopub.execute_input":"2022-05-09T08:08:25.736465Z","iopub.status.idle":"2022-05-09T08:08:25.743007Z","shell.execute_reply.started":"2022-05-09T08:08:25.736427Z","shell.execute_reply":"2022-05-09T08:08:25.742251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import packages","metadata":{"id":"HNe7QU7n7cqh"}},{"cell_type":"code","source":"import random\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torchvision.models as models\nfrom torch.optim import Adam, AdamW\nfrom qqdm import qqdm, format_str\nimport pandas as pd","metadata":{"id":"Jk3qFK_a7k8P","execution":{"iopub.status.busy":"2022-05-09T08:08:25.745319Z","iopub.execute_input":"2022-05-09T08:08:25.745753Z","iopub.status.idle":"2022-05-09T08:08:25.754344Z","shell.execute_reply.started":"2022-05-09T08:08:25.745719Z","shell.execute_reply":"2022-05-09T08:08:25.753573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading data","metadata":{"id":"6X6fkGPnYyaF"}},{"cell_type":"code","source":"train = np.load('../input/ml2022spring-hw8/data/trainingset.npy', allow_pickle=True)\ntest = np.load('../input/ml2022spring-hw8/data/testingset.npy', allow_pickle=True)\n\nprint(train.shape)\nprint(test.shape)","metadata":{"id":"k7Wd4yiUYzAm","execution":{"iopub.status.busy":"2022-05-09T08:08:25.756599Z","iopub.execute_input":"2022-05-09T08:08:25.757051Z","iopub.status.idle":"2022-05-09T08:08:26.588779Z","shell.execute_reply.started":"2022-05-09T08:08:25.757016Z","shell.execute_reply":"2022-05-09T08:08:26.588003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random seed\nSet the random seed to a certain value for reproducibility.","metadata":{"id":"_flpmj6OYIa6"}},{"cell_type":"code","source":"def same_seeds(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\nsame_seeds(48763)","metadata":{"id":"Gb-dgXQYYI2Q","execution":{"iopub.status.busy":"2022-05-09T08:08:26.591543Z","iopub.execute_input":"2022-05-09T08:08:26.591744Z","iopub.status.idle":"2022-05-09T08:08:26.599847Z","shell.execute_reply.started":"2022-05-09T08:08:26.591719Z","shell.execute_reply":"2022-05-09T08:08:26.599075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Autoencoder","metadata":{"id":"zR9zC0_Df-CR"}},{"cell_type":"markdown","source":"# Models & loss","metadata":{"id":"1EbfwRREhA7c"}},{"cell_type":"code","source":"class fcn_autoencoder(nn.Module):\n    def __init__(self):\n        super(fcn_autoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(64 * 64 * 3, 128),\n            nn.ReLU(),\n            nn.Linear(128, 32),\n            nn.ReLU(), \n            nn.Linear(32, 8),\n            nn.ReLU(), \n            nn.Linear(8, 3)\n        )\n        \n        self.decoder = nn.Sequential(\n            nn.Linear(3, 8),\n            nn.ReLU(), \n            nn.Linear(8, 32),\n            nn.ReLU(),\n            nn.Linear(32, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64 * 64 * 3), \n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x\n\n\n\nclass conv_autoencoder(nn.Module):    # loss : 0.01\n    def __init__(self):\n        super(conv_autoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 12, 4, stride=2, padding=1),         \n            nn.ReLU(),\n            nn.Conv2d(12, 24, 4, stride=2, padding=1),        \n            nn.ReLU(),\n            nn.Conv2d(24, 48, 4, stride=2, padding=1),         \n            nn.ReLU(),\n        )\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(24, 12, 4, stride=2, padding=1), \n            nn.ReLU(),\n            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),\n            nn.Tanh(),\n        )\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x\n    \n    \nclass multi_fcn(nn.Module):\n    def __init__(self):\n        super(multi_fcn, self).__init__()\n        self.encoder_1 = nn.Sequential(\n            nn.Linear(64 * 64 * 3, 256),\n            nn.ReLU(),\n            nn.Linear(256, 64),\n            nn.ReLU(), \n            nn.Linear(64, 32), \n            nn.ReLU(), \n            nn.Linear(32, 12),\n            nn.ReLU(), \n            nn.Linear(12, 3)\n        )\n        self.encoder_2 = nn.Sequential(\n            nn.Linear(64 * 64 * 3, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU(), \n            nn.Linear(64, 12), \n            nn.ReLU(), \n            nn.Linear(12, 3)\n        )\n        self.encoder_3 = nn.Sequential(\n            nn.Linear(64 * 64 * 3, 128),\n            nn.ReLU(),\n            nn.Linear(128, 32),\n            nn.ReLU(), \n            nn.Linear(32, 3)\n        )\n        self.encoder_4 = nn.Sequential(\n            nn.Linear(64 * 64 * 3, 256),\n            nn.ReLU(),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU(), \n            nn.Linear(64, 32), \n            nn.ReLU(), \n            nn.Linear(32, 12),\n            nn.ReLU(), \n            nn.Linear(12, 3)\n        )\n        self.encoder_5 = nn.Sequential(\n            nn.Linear(64 * 64 * 3, 64),\n            nn.ReLU(),\n            nn.Linear(64, 3)\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(15, 24),\n            nn.ReLU(), \n            nn.Linear(24, 64),\n            nn.ReLU(),\n            nn.Linear(64, 128),\n            nn.ReLU(), \n            nn.Linear(128, 64 * 64 * 3), \n            nn.Tanh()\n        )\n    def forward(self, x):\n        x1 = self.encoder_1(x)\n        x2 = self.encoder_2(x)\n        x3 = self.encoder_3(x)\n        x4 = self.encoder_4(x)\n        x5 = self.encoder_5(x)\n        x = torch.cat((x1,x2,x3,x4,x5), dim=1)\n        y = self.decoder(x)\n        return y\n        \n    \n\nclass VAE(nn.Module):\n    def __init__(self):\n        super(VAE, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 12, 4, stride=2, padding=1),            \n            nn.ReLU(),\n            nn.Conv2d(12, 24, 4, stride=2, padding=1),    \n            nn.ReLU(),\n        )\n        self.enc_out_1 = nn.Sequential(\n            nn.Conv2d(24, 48, 4, stride=2, padding=1),  \n            nn.ReLU(),\n        )\n        self.enc_out_2 = nn.Sequential(\n            nn.Conv2d(24, 48, 4, stride=2, padding=1),\n            nn.ReLU(),\n        )\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(48, 24, 4, stride=2, padding=1), \n            nn.ReLU(),\n            nn.ConvTranspose2d(24, 12, 4, stride=2, padding=1), \n            nn.ReLU(),\n            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1), \n            nn.Tanh(),\n        )\n\n    def encode(self, x):\n        h1 = self.encoder(x)\n        return self.enc_out_1(h1), self.enc_out_2(h1)\n\n    def reparametrize(self, mu, logvar):\n        std = logvar.mul(0.5).exp_()\n        if torch.cuda.is_available():\n            eps = torch.cuda.FloatTensor(std.size()).normal_()\n        else:\n            eps = torch.FloatTensor(std.size()).normal_()\n        eps = Variable(eps)\n        return eps.mul(std).add_(mu)\n\n    def decode(self, z):\n        return self.decoder(z)\n\n    def forward(self, x):\n        mu, logvar = self.encode(x)\n        z = self.reparametrize(mu, logvar)\n        return self.decode(z), mu, logvar\n        \n    \n    \ndef loss_vae(recon_x, x, mu, logvar, criterion):\n    \"\"\"\n    recon_x: generating images\n    x: origin images\n    mu: latent mean\n    logvar: latent log variance\n    \"\"\"\n    mse = criterion(recon_x, x)\n    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n    KLD = torch.sum(KLD_element).mul_(-0.5)\n    return mse + KLD","metadata":{"id":"Wi8ds1fugCkR","execution":{"iopub.status.busy":"2022-05-09T08:08:26.601544Z","iopub.execute_input":"2022-05-09T08:08:26.602064Z","iopub.status.idle":"2022-05-09T08:08:26.637482Z","shell.execute_reply.started":"2022-05-09T08:08:26.602027Z","shell.execute_reply":"2022-05-09T08:08:26.636841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset module\n\nModule for obtaining and processing data. The transform function here normalizes image's pixels from [0, 255] to [-1.0, 1.0].\n","metadata":{"id":"vrJ9bScg9AgO"}},{"cell_type":"code","source":"class CustomTensorDataset(TensorDataset):\n    \"\"\"TensorDataset with support of transforms.\n    \"\"\"\n    def __init__(self, tensors):\n        self.tensors = tensors\n        if tensors.shape[-1] == 3:\n            self.tensors = tensors.permute(0, 3, 1, 2)\n        \n        self.transform = transforms.Compose([\n          transforms.Lambda(lambda x: x.to(torch.float32)),\n          transforms.Lambda(lambda x: 2. * x/255. - 1.),\n        ])\n        \n    def __getitem__(self, index):\n        x = self.tensors[index]\n        \n        if self.transform:\n            # mapping images to [-1.0, 1.0]\n            x = self.transform(x)\n\n        return x\n\n    def __len__(self):\n        return len(self.tensors)","metadata":{"id":"33fWhE-h9LPq","execution":{"iopub.status.busy":"2022-05-09T08:08:26.638771Z","iopub.execute_input":"2022-05-09T08:08:26.639249Z","iopub.status.idle":"2022-05-09T08:08:26.650137Z","shell.execute_reply.started":"2022-05-09T08:08:26.639212Z","shell.execute_reply":"2022-05-09T08:08:26.649469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"id":"XKNUImqUhIeq"}},{"cell_type":"markdown","source":"## Configuration\n","metadata":{"id":"7ebAJdjFmS08"}},{"cell_type":"code","source":"# Training hyperparameters\nnum_epochs = 50\nbatch_size = 2000\nlearning_rate = 1e-3\n\n# Build training dataloader\nx = torch.from_numpy(train)\ntrain_dataset = CustomTensorDataset(x)\n\ntrain_sampler = RandomSampler(train_dataset)\ntrain_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n\n# Model\nmodel_type = 'multi'   # selecting a model type from {'cnn', 'fcn', 'vae', 'multi'}\nmodel_classes = {'fcn': fcn_autoencoder(), 'cnn': conv_autoencoder(), 'vae': VAE(), 'multi': multi_fcn()}\nmodel = model_classes[model_type].cuda()\n\n# Loss and optimizer\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"id":"in7yLfmqtZTk","execution":{"iopub.status.busy":"2022-05-09T08:08:26.652376Z","iopub.execute_input":"2022-05-09T08:08:26.652878Z","iopub.status.idle":"2022-05-09T08:08:26.803109Z","shell.execute_reply.started":"2022-05-09T08:08:26.652829Z","shell.execute_reply":"2022-05-09T08:08:26.802409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training loop","metadata":{"id":"wyooN-JPm8sS"}},{"cell_type":"code","source":"best_loss = np.inf\nmodel.train()\n\nqqdm_train = qqdm(range(num_epochs), desc=format_str('bold', 'Description'))\nfor epoch in qqdm_train:\n    tot_loss = list()\n    for data in train_dataloader:\n\n        # ===================loading=====================\n        img = data.float().cuda()\n        if model_type in ['fcn', 'multi']:\n            img = img.view(img.shape[0], -1)\n\n        # ===================forward=====================\n        output = model(img)\n        if model_type in ['vae']:\n            loss = loss_vae(output[0], img, output[1], output[2], criterion)\n        else:\n            loss = criterion(output, img)\n\n        tot_loss.append(loss.item())\n        # ===================backward====================\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    # ===================save_best====================\n    mean_loss = np.mean(tot_loss)\n    if mean_loss < best_loss:\n        best_loss = mean_loss\n        torch.save(model, 'best_model_{}.pt'.format(model_type))\n    # ===================log========================\n    qqdm_train.set_infos({\n        'epoch': f'{epoch + 1:.0f}/{num_epochs:.0f}',\n        'loss': f'{mean_loss:.4f}',\n    })\n    # ===================save_last========================\n    torch.save(model, 'last_model_{}.pt'.format(model_type))","metadata":{"id":"JoW1UrrxgI_U","execution":{"iopub.status.busy":"2022-05-09T08:08:26.805765Z","iopub.execute_input":"2022-05-09T08:08:26.80599Z","iopub.status.idle":"2022-05-09T08:17:04.694363Z","shell.execute_reply.started":"2022-05-09T08:08:26.805959Z","shell.execute_reply":"2022-05-09T08:17:04.693559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference\nModel is loaded and generates its anomaly score predictions.","metadata":{"id":"Wk0UxFuchLzR"}},{"cell_type":"markdown","source":"## Initialize\n- dataloader\n- model\n- prediction file","metadata":{"id":"evgMW3OwoGqD"}},{"cell_type":"code","source":"eval_batch_size = 200\n\n# build testing dataloader\ndata = torch.tensor(test, dtype=torch.float32)\ntest_dataset = CustomTensorDataset(data)\ntest_sampler = SequentialSampler(test_dataset)\ntest_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=eval_batch_size, num_workers=1)\neval_loss = nn.MSELoss(reduction='none')\n\n# load trained model\ncheckpoint_path = f'last_model_{model_type}.pt'\nmodel = torch.load(checkpoint_path)\nmodel.eval()\n\n# prediction file \nout_file = 'prediction.csv'","metadata":{"id":"_MBnXAswoKmq","execution":{"iopub.status.busy":"2022-05-09T08:17:04.697025Z","iopub.execute_input":"2022-05-09T08:17:04.697507Z","iopub.status.idle":"2022-05-09T08:17:05.414357Z","shell.execute_reply.started":"2022-05-09T08:17:04.697474Z","shell.execute_reply":"2022-05-09T08:17:05.413594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"anomality = list()\nwith torch.no_grad():\n    for i, data in enumerate(test_dataloader):\n        img = data.float().cuda()\n        if model_type in ['fcn', 'multi']:\n            img = img.view(img.shape[0], -1)\n        output = model(img)\n        if i == 0:\n            temp = output\n        if model_type in ['vae']:\n            output = output[0]\n        if model_type in ['fcn', 'multi']:\n            loss = eval_loss(output, img).sum(-1)\n        else:\n            loss = eval_loss(output, img).sum([1, 2, 3])\n        anomality.append(loss)\nanomality = torch.cat(anomality, axis=0)\nanomality = torch.sqrt(anomality).reshape(len(test), 1).cpu().numpy()\n\ndf = pd.DataFrame(anomality, columns=['score'])\ndf.to_csv(out_file, index_label = 'ID')","metadata":{"id":"_1IxCX2iCW6V","execution":{"iopub.status.busy":"2022-05-09T08:17:05.415554Z","iopub.execute_input":"2022-05-09T08:17:05.416321Z","iopub.status.idle":"2022-05-09T08:17:07.630135Z","shell.execute_reply.started":"2022-05-09T08:17:05.41628Z","shell.execute_reply":"2022-05-09T08:17:07.629273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### For the reportï¼š","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\nImage.fromarray(test[109])","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:17:07.631838Z","iopub.execute_input":"2022-05-09T08:17:07.632092Z","iopub.status.idle":"2022-05-09T08:17:07.639908Z","shell.execute_reply.started":"2022-05-09T08:17:07.632064Z","shell.execute_reply":"2022-05-09T08:17:07.639093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tensor = torch.from_numpy(test[109]).cuda().float().view(-1)\nx = model.encoder(tensor)\nprint(x)\nx[1] = x[1] /2 \nprint(x)\ny = model.decoder(x)\ny = y.view(3,64,64).permute(1,2,0)\nout = y.cpu().detach().numpy()*255\nout = out.astype(np.uint8)\nImage.fromarray(out)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:17:07.641374Z","iopub.execute_input":"2022-05-09T08:17:07.641845Z","iopub.status.idle":"2022-05-09T08:17:07.668394Z","shell.execute_reply.started":"2022-05-09T08:17:07.641808Z","shell.execute_reply":"2022-05-09T08:17:07.666508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}